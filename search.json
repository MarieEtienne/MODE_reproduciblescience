[
  {
    "objectID": "prior_course.html",
    "href": "prior_course.html",
    "title": "Be ready for the course",
    "section": "",
    "text": "The Online Collaborative Resources (OCR) class will make intensive use of the Reproducible Science tools. For this class and as an investment for the future, you will need to:"
  },
  {
    "objectID": "prior_course.html#git-on-your-computer",
    "href": "prior_course.html#git-on-your-computer",
    "title": "Be ready for the course",
    "section": "Git on your computer",
    "text": "Git on your computer\nInstall Git on your personal computer: Go to the Git website and click on the computer screen on the right, which should offer you the version suitable for your operating system."
  },
  {
    "objectID": "prior_course.html#github-account",
    "href": "prior_course.html#github-account",
    "title": "Be ready for the course",
    "section": "GitHub account",
    "text": "GitHub account\nIf you don’t have one, you have to create a GitHub account and set up the link between your computer and the GitHub. Be careful with the login you choose, this account will be used professionally and you may want to avoid pseudo like toto2024, or ladybug288.\nGitHub is just one solution to share git repositories online, you may work later with gitlab with is very similar to GitHub."
  },
  {
    "objectID": "prior_course.html#a-ssh-connection",
    "href": "prior_course.html#a-ssh-connection",
    "title": "Be ready for the course",
    "section": "A SSH connection",
    "text": "A SSH connection\nTo have smooth interactions with Github, you have to use a SSH and to do so, you will to generate SSH key on your computer and copy paste the public SSH key id_rsa.pub on your GitHub account.\n\nOpen a terminal (any terminal on Mac and Linux, the Git bash program you have installed with git if you are using Windows)\ntype the command\nssh-keygen\nDO NOT ENTER ANY PASSPHRASE while asked, simply press enter (twice generally)\nYou should have a directory named .ssh in your main personnal folder. Open the file id_rsa.pub with any text basic editor (like notepad, gedit …) and copy the key.\nGo to the settings of your GitHub account, choose the SSH and GPG keys, then press New SSH key and paste the previously copied key."
  },
  {
    "objectID": "prior_course.html#let-me-know-who-you-are",
    "href": "prior_course.html#let-me-know-who-you-are",
    "title": "Be ready for the course",
    "section": "Let me know who you are",
    "text": "Let me know who you are\nPlease enter your name and GitHub login on this spreadsheet and indicate in the last column whether you are already familiar with some markup languages (markdown, HTML) and if you have prior experience with Git or any version control system.\nPlease try to install all of this as soon as possible, and if you encounter any difficulties, don’t hesitate to contact me by email or come to me at the beginning of the class.\nIt will be easier if you can follow this procedure on your laptop and bring it to the class, but if you don’t have any laptop we will able to use the computers in the classroom (however this tedious installation process will have to be repeated on your personal computer)"
  },
  {
    "objectID": "python_chapter.html",
    "href": "python_chapter.html",
    "title": "Chapter : statistical tests with dependent data",
    "section": "",
    "text": "This chapter is a simple example using python\nYou can import python libraries using the code\n\nimport pandas as pd\nimport numpy as np\n\nand then describe the purpose of your chapter as well as executing python command.\nFor example a basic summary of a dataset is given by\n\ndf = pd.read_csv(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\")\n\nand produce a graph\n\ndf.boxplot(by = 'species', column = 'body_mass_g')  \n\n&lt;Axes: title={'center': 'body_mass_g'}, xlabel='species'&gt;"
  },
  {
    "objectID": "simple_chapter.html",
    "href": "simple_chapter.html",
    "title": "A simple chapter with no code",
    "section": "",
    "text": "This chapter is a simple example of qmd format"
  },
  {
    "objectID": "simple_chapter.html#subsection",
    "href": "simple_chapter.html#subsection",
    "title": "A simple chapter with no code",
    "section": "subsection",
    "text": "subsection\na list\n\nblabla\nblabla 2\nblabla 3"
  },
  {
    "objectID": "r_chapter.html",
    "href": "r_chapter.html",
    "title": "Mixed models in ecology",
    "section": "",
    "text": "Odin\n\n\nLouis\n\n\nAbdou\n\n\nAntoine\n#Ael\nThis chapter is a simple example using R\nYou can import R package using the code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nand then describe the purpose of your chapter as well as executing R command.\nFor example a basic summary of a dataset is given by\n\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n\nand produce a graph\n\ndf %&gt;% ggplot() +\n    aes(x=species, y = body_mass_g) +\n    geom_boxplot()  \n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nA citation (bauer2023writing?)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The book we dreamt we had",
    "section": "",
    "text": "This website is produced by the M2 MODE student uring year 2023-2024 as part of their assignment in the Online Collaborative Ressources course.\nAfter a short introduction regarding the principles and the tools of a reproducible science, they have been collaborating to write a M1 companion book for the next student generation.\nTable of Contents\n\nMixed models in Ecology\nDependent Data\nBayesian models"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "How to contribute",
    "section": "",
    "text": "Create a specific branch for your chapter named an_explicit_name_for_the_branch and switch on this branch\n\ngit checkout -b an_explicit_name_for_the_branch\nIn the development of the project, you might find necessary to have several branches per chapter.\n\nCreate a quarto file for the chapter chapter0.qmd in your branch\n\ngit add chapter0.qmd\ngit commit -m \"first commit in the chapter branch\"\n\nPush everything on the remote repo on Github\n\nFor the first push after the branch creation, you have to specify the name of the branch on the remote repo and you can use git  push --set-upstream origin an_explicit_name_for_the_branch or\nFor the push to come after the first one, you will simply push by\ngit  push\nOnce you are quite happy with your production, you will be willing to integrate your production on the main branch. A good practice is to ask the permission to push on the main branch, which is named a pull request (PR).\n\nAsk for a PR on Github\nIf needed, specify in the PR message the package you need and mention MarieEtienne as reviewer of the PR.\n\nA mock rendering of the qmd file will start when you request a PR using the Github Action mechanism (called runner on gitlab). If the action passes (green signal), you can go to the next step. If not, you will have to fix the issue (again you can ask assistance if you don’t understand the error).\n\nOnce the PR is checked, mention one of your colleage as reviewer."
  },
  {
    "objectID": "instructions.html#one-chapter-corresponds-at-least-to-one-branch",
    "href": "instructions.html#one-chapter-corresponds-at-least-to-one-branch",
    "title": "How to contribute",
    "section": "",
    "text": "Create a specific branch for your chapter named an_explicit_name_for_the_branch and switch on this branch\n\ngit checkout -b an_explicit_name_for_the_branch\nIn the development of the project, you might find necessary to have several branches per chapter.\n\nCreate a quarto file for the chapter chapter0.qmd in your branch\n\ngit add chapter0.qmd\ngit commit -m \"first commit in the chapter branch\"\n\nPush everything on the remote repo on Github\n\nFor the first push after the branch creation, you have to specify the name of the branch on the remote repo and you can use git  push --set-upstream origin an_explicit_name_for_the_branch or\nFor the push to come after the first one, you will simply push by\ngit  push\nOnce you are quite happy with your production, you will be willing to integrate your production on the main branch. A good practice is to ask the permission to push on the main branch, which is named a pull request (PR).\n\nAsk for a PR on Github\nIf needed, specify in the PR message the package you need and mention MarieEtienne as reviewer of the PR.\n\nA mock rendering of the qmd file will start when you request a PR using the Github Action mechanism (called runner on gitlab). If the action passes (green signal), you can go to the next step. If not, you will have to fix the issue (again you can ask assistance if you don’t understand the error).\n\nOnce the PR is checked, mention one of your colleage as reviewer."
  },
  {
    "objectID": "instructions.html#as-a-reviewer",
    "href": "instructions.html#as-a-reviewer",
    "title": "How to contribute",
    "section": "As a reviewer",
    "text": "As a reviewer\nYour role is essential as you are responsible for the quality of the submission you were assigned to. Read carefully the production and ask for correction/clarification if needed. One you are happy with the correction you can accept the PR."
  },
  {
    "objectID": "Mixed_models.html",
    "href": "Mixed_models.html",
    "title": "Mixed models in ecology",
    "section": "",
    "text": "library(nlme)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(predictmeans)\n\nLoading required package: glmmTMB\n\n\nWarning in checkMatrixPackageVersion(getOption(\"TMB.check.Matrix\", TRUE)): Package version inconsistency detected.\nTMB was built with Matrix version 1.6.4\nCurrent Matrix version is 1.6.1.1\nPlease re-install 'TMB' from source using install.packages('TMB', type = 'source') or ask CRAN for a binary version of 'TMB' matching CRAN's 'Matrix' package\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'lme4'\n\n\nThe following object is masked from 'package:nlme':\n\n    lmList\n\n\nLoading required package: lmerTest\n\n\n\nAttaching package: 'lmerTest'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(sp)"
  },
  {
    "objectID": "Mixed_models.html#introduction",
    "href": "Mixed_models.html#introduction",
    "title": "Mixed models in ecology",
    "section": "Introduction",
    "text": "Introduction\nGeneral Linear Models, such as linear regressions, ANOVA, and ANCOVA, are commonly employed to depict the relationships between a dependent variable, denoted as (Y), and one or more independent variables (\\(X_1, X_2, ..., X_n\\)).  These models are based on several assumptions, including homoscedasticity of the variance, non-collinearity of residuals, and normality of residuals. Generalized Linear Models (GLMs) can address homoscedasticity and normality assumptions by accommodating data from different distributions like Poisson, binomial, or Gamma distributions, which are often encountered in ecology.   However, it is crucial to validate the non-collinearity of residuals.\nIn biological and ecological experiments, the assumption of independence of measurements, necessary for non-collinearity of residuals, is frequently violated.  This is because measurements are often correlated within families, regions, repeated on the same individuals, or across time and sites. In such cases, it becomes necessary to employ mixed models. These models, extensions of both general and generalized linear models, consider the correlation of measurements by introducing individuals, regions, families, or other factors as random effects in the models. This incorporation allows for a more accurate representation of the complex dependencies present in the data.\nWhat is a random effect, and how do I determine if my effect is random or fixed ?\nTo clarify the distinction between fixed and random effects, let’s examine two examples:\n\nExample 1: Comparing individual cars\nAbdel, Antonio, Odeline, and Aela want to compare the oil consumption of their individual cars. They conduct a test by measuring oil consumption during a 30-kilometer drive, repeated five times in a day, with consistent traffic conditions and driving patterns.  The data set consists of one factor with four levels (representing the four cars) and five replicates each. Performing a one-way ANOVA allows them to determine which car is the most economical. In this scenario, the factor “car” is fixed, and the analysis provides conclusions specific to the four studied cars.\nExample 2: Assessing homogeneity within a car model\nA car constructor aims to evaluate the homogeneity of oil consumption within a car model, treating the model as a population of cars with expected heterogeneity in gas consumption.  Similar to Example 1, they measure oil consumption by driving each car 30 kilometers, five times in a day, resulting in a data set with one factor and four levels, each with five replicates. Unlike the first example, the cars in this case were sampled from a larger population, and the objective is to draw conclusions about the entire population, not just the sampled cars. Here, a mixed model with the factor ‘car’ as a random factor should be used.\n\nIn summary, a factor is designated as fixed when the experimenter intentionally chooses a limited number of levels for investigation, aiming to assess the impact of each level on the response variable. A factor is considered random when the selected levels represent only a sample from all possible levels. In this case, the objective is to understand the variability in the response variable attributed to this factor.\nFor example, let’s consider a researcher investigating the influence of the number of training sessions per week on the concentration of red blood cells in recreational athletes. The researcher collects data from 50 athletes in a local club who train between 1 and 5 times a week. Initially planning a simple ANOVA with the number of training sessions as the main factor, the researcher discovers that most athletes in the data set belong to only 10 families, leading to non-independent measurements. To address this issue, the researcher opts for a mixed model, treating the number of training sessions as a fixed factor and the family as a random factor. This approach allows the exploration of variability between families without the intention of directly comparing them.\nNow that we have a general understanding of what mixed models are, we can delve into the mathematical formalism of these models. In this chapter, you will discover how matrices can be employed to create mixed models, explore the various dependency structures that exist, and ultimately, find an implementation of mixed models in R."
  },
  {
    "objectID": "Mixed_models.html#formalization-of-the-linear-mixed-model",
    "href": "Mixed_models.html#formalization-of-the-linear-mixed-model",
    "title": "Mixed models in ecology",
    "section": "1. Formalization of the linear mixed model",
    "text": "1. Formalization of the linear mixed model\nThe linear mixed model can be formulated as follows:\n\\[\nY_{i} = \\beta X_{i} + \\gamma_i Z_{i} + \\varepsilon_{i}\n\\]\nwhere:\n\n\\(Y_i = n_i \\times 1\\) measurements for subject \\(i\\), where \\(n\\) is the number of observations\n\\(X_i = n_i \\times p\\) matrix of vectors for fixed effects, where \\(p\\) is the number of fixed parameters\n\\(\\beta_i= p \\times 1\\) parameters for fixed effects\n\\(Z_i = n_i \\times p\\) matrix of vectors for random effects\n\\(\\gamma_i = r \\times 1\\) parameters for random effects, where \\(p\\) is the number of random parameters\n\\(\\varepsilon_i = n_i \\times 1\\) residuals for individual \\(i\\)\n\n(Giorgi 2020)\nA mixed effects model incorporates random effects (\\(\\gamma_i\\)), or a combination of both random and fixed effects (\\(\\beta\\)), whereas a standard linear model includes only fixed effects.\nWhen it is clear that the researcher intends to compare particular, predefined levels of a treatment, those levels are considered fixed effects. Conversely, when the levels of the treatment are drawn from a larger population of possible levels, the treatment is treated as a random effect.\nIn addition, random effects are included in a model when there is a correlation or dependence among the observations that cannot be ignored.\nRANDOM VARIABLE = “something that could not be known before sampling/measurement/observation”.\nIn matrix form, the mixed model is written as:\n\\[\nY \\sim \\mathcal{N{n}}(X\\theta, \\Sigma)\n\\] where:\n\\(Y\\) is the response vector of the observations, \\(X\\theta\\) is the expectation of the response vector \\(Y\\) and \\(\\Sigma\\) is the variance matrix.\nWe can note that if the response vector \\(Y\\) is of dimension \\(n\\), the matrix \\(\\Sigma\\) is of dimensions \\(n \\times n\\). Since \\(\\Sigma\\) is symmetric, it comprises \\(n(n + 1)/2\\) parameters. This is because, in a symmetric matrix, the elements above (or below) the main diagonal are the same as those below (or above), reducing the total number of parameters needed to describe the matrix.\nHowever, the limitation of the available data prevents considering models where all these \\(n(n + 1)/2\\) parameters are free. This restriction arises from the need to have a significant amount of data to reliably estimate each parameter, which quickly becomes unrealistic with a limited dataset.\nTo address this issue, the linear mixed-effects model proposes an approach where a structure is imposed on the variance matrix \\(\\Sigma\\). This structure, governed by a limited number of parameters called “variance parameters,” denoted \\(\\psi\\), reduces the number of parameters needed to describe the covariance matrix. Consequently, the model can be realistically adapted even with a limited amount of data, while accounting for the correlation between observations within the framework of linear mixed-effects models. The model parameters include \\(\\theta\\) for the expectation and \\(\\psi\\) for the variance."
  },
  {
    "objectID": "Mixed_models.html#matrix-computation-in-mixed-models",
    "href": "Mixed_models.html#matrix-computation-in-mixed-models",
    "title": "Mixed models in ecology",
    "section": "2. Matrix computation in mixed models",
    "text": "2. Matrix computation in mixed models\nIt is possible to encounter (mixed) linear models written under their matrix form, for their concision. It is therefore natural to present this form in the context of mixed models.\nAs a reminder, a linear model, like linear regression, with \\(p\\) explanatory variables can be written \\[y_i = \\beta_0 + \\beta_1x_i^{(1)} + \\ldots + \\beta_px_i^{(p)} + \\varepsilon_i\\], where \\(y_i\\) represent an observation of the response variable \\(Y\\) for the individual \\(i\\), \\(\\beta_0\\) the intercept, \\(\\beta_1,...,\\beta_p\\) the coefficients associated to each explanatory variable \\(X_1,...,X_p\\), \\(x_i^{(1)},...,x_i^{(p)}\\) the \\(p\\) observations (for the \\(p\\) explanatory variables) for the individual \\(i\\), and \\(e_i\\) an error term associated to the individual \\(i\\).  We can see \\(e_i\\) as a realization of a random variable \\(E_i\\) distributed according to a normal law \\(\\mathcal{N}(0,\\sigma^2)\\). Noting \\[y=\\begin{pmatrix}\ny_1\\\\\n\\vdots\\\\\ny_n\\\\\n\\end{pmatrix}\\], \\[X=\\begin{pmatrix}\n1&x_1^{(1)} & \\ldots & x_1^{(p)}\\\\\n\\vdots & \\vdots & \\ldots & \\vdots \\\\\n1 & x_n^{(1)} & \\ldots & x_n^{(p)}\n\\end{pmatrix}\\], \\[\\theta=\\begin{pmatrix}\n\\beta_0\\\\\n\\vdots\\\\\n\\beta_p\\\\\n\\end{pmatrix}\\] and \\[e=\\begin{pmatrix}\n\\varepsilon_1\\\\\n\\vdots\\\\\n\\varepsilon_n\\\\\n\\end{pmatrix}\\], we can rewrite the previous model under the form \\[y=X\\theta+e\\]Here, \\(e\\) is a vector of \\(n\\) independent realizations or a random variable \\(E_i\\) following a normal distribution \\(\\mathcal{N}(0,\\sigma^2)\\).  Hence, \\(e\\) is a realization of a random variable \\(E\\) following the distribution \\(\\mathcal{N}_n(0,\\sigma^2I_n)\\) (\\(e_i\\) is an observation of the random variable \\(E_i\\) distributed according to a normal law \\(\\mathcal{N}(0,\\sigma^2)\\)).  Similarly, \\(y\\) is an observation of \\(Y=X\\theta+E\\) where \\(Y\\sim\\mathcal{N}_n(X\\theta,\\sigma^2I_n)\\) (\\(y_i\\) is an observation of \\(Y_i\\) distributed according to a normal law \\(\\mathcal{N}((X\\theta)_i,\\sigma^2)\\)). Hence, by introducing \\(Y\\) and \\(E\\), the previous model can be written \\(Y=X\\theta+E\\) where \\(\\mathrm{E}\\stackrel{iid}\\sim\\mathcal{N}_n(0,\\sigma^2I_n)\\).\nBy definition, the mean response is equal to \\(X\\theta\\), more or less an error term equals to 0 in average but that varies of \\(\\sigma^2I_n\\). Thus, we can write \\[Y\\sim\\mathcal{N}_n(X\\theta,\\sigma^2I_n)\\]We note that when writing \\(\\mathrm{E}\\stackrel{iid}\\sim\\mathcal{N}_n(0,\\sigma^2I_n)\\), each error has got the same variance (\\(\\sigma^2\\)) because every samples are independent. We will see subsequently that if this independence condition is not respected, all the errors do not have the same variance, we speak of a dependence structure. The dependence between the measurements determines the dependence structure (measurements repeated over time, individuals grouped by common ancestry, etc.). We will see here that in the context of mixed models, the previous equation is written \\[Y\\sim\\mathcal{N}_n(X\\theta,\\sum)\\]. When writing this, we note that the average response does not change. Generalization concerns errors. Now, let’s study study the components of variance \\(\\sum\\) by following an example. We decide to study the heritability of a trait (height for example). We want to see if individuals from one ascendant are more similar than those from another ascendant. We have \\(m\\) ascendants, numbered \\(i=1,...,m\\), from a larger population, each having \\(n\\) descendants numbered \\(j=1,...,n\\). We pose \\(Y_{ij}=\\) the trait value for the j-ème descendant of the i-ème ascendant. Individuals with the same ascendant are therefore grouped by their belonging to the same ascendant. The fact of sampling ancestors from a larger population (random effect) introduces a correlation between the traits measured on the descendants of the same ancestor. This correlation is uniform between individuals. The descendants between the groups (for different ancestors) are independent. Thus, we write \\[\n\\mathbb{Cov}(Y_{ij},Y_{i'j'}) = \\left\\{\n    \\begin{array}{ll}\n        \\gamma^2 & \\mbox{si } i=i'\\\\\n        0 & \\mbox{sinon.}\n    \\end{array}\n\\right.\n\\] This model therefore includes a variance associated with the ascendant effect \\(\\gamma^2\\) and a residual variance \\(\\sigma^2\\). We precise that \\(\\gamma^2\\) represent the variability between the ascendants. Starting from the linear model \\(Y=X\\theta+E\\) where \\(E\\) is still \\(\\sigma^2I_n\\), we just have to take into account this variance associated with the ascendant effect. To do this, we introduce the matrix \\(Z\\), of dimension \\(n\\times m\\), where \\[\nZ_{a,i} = \\left\\{\n    \\begin{array}{ll}\n        1 & \\mbox{l'individu } a=(i,j) \\mbox{ est le descendant de l'ascendant }i\\\\\n        0 & \\mbox{sinon.}\n    \\end{array}\n\\right.\n\\] and the vector \\(U\\) of dimension \\(m\\) including the random effects \\(\\gamma^2\\). Hence, the previous model can be rewritten \\(Y=X\\theta+ZU+E\\). We remind that \\(U\\) and \\(E\\) are independents, gaussiens centered, and that \\(\\mathbb{Var}(U)=\\gamma^2I_m\\). Consequently, \\(\\mathbb{E}(Y)=X\\theta\\) and \\(\\sum = \\mathbb{V}(Y)=Z\\mathbb{V}(U)Z'+\\mathbb{V}(E) = \\gamma^2ZZ'+\\sigma^2(I_n)\\). We get back to the matrix form \\(Y\\sim\\mathcal{N}(X\\theta,\\sum)\\) with \\[\\sum=\\begin{pmatrix}\nR&0 & \\ldots & 0\\\\\n0 & \\ddots & \\ddots & 0 \\\\\n\\vdots & \\ddots & \\ddots & 0 \\\\\n0 & \\ldots & 0 & R\n\\end{pmatrix}\\], where \\[R=\\begin{pmatrix}\n\\sigma^2+\\gamma^2&\\gamma^2 & \\ldots & \\gamma^2\\\\\n\\gamma^2 & \\ddots & \\ddots & \\gamma^2 \\\\\n\\vdots & \\ddots & \\ddots & \\gamma^2 \\\\\n\\gamma^2 & \\ldots & \\gamma^2 & \\sigma^2+\\gamma^2\n\\end{pmatrix}\\]\\(R\\) corresponds to the representation of the variances due to the random effect and residuals. Note that the diagonal blocks are of the same dimensions if the number of descendants is identical for each ascendant."
  },
  {
    "objectID": "Mixed_models.html#dependency-structures",
    "href": "Mixed_models.html#dependency-structures",
    "title": "Mixed models in ecology",
    "section": "3. Dependency structures",
    "text": "3. Dependency structures\nThis part of the chapter is inspired by (L. Bel 2016)’s book. \n\n3.1 Case of repeated measurements\nWe want to evaluate the effect of different diet on weight gain in rats. Several animals (\\(j\\)) follow each diet (\\(i\\)), and they kept the same diet across all the experiment. Each week animal weight (\\(Y_{ij}\\)) is measured, during T weeks. In this case, measures are repeated across time, such measurements are called longitudinal data.  To analyse this data, the temporal dependency must be taken into account, for this, the following model can be used: \nModel The model proposed here takes into account the kinetic aspect of the experiment and predicts that the dependence between two measurements depends on the time interval between them.    We assume that the weights are Gaussian with the following expected values :\n\\[ E(Y_{ijt}) = µ + α_i + γ_t + (αγ)_{it}.\\]\nDependency structure We assume that all measurements have the same variance\n\\[ V(Y_{ijt} =  σ^2) \\]\nand the covariance between them is\n\\[Cov(Y_{ijt}, Y_{i'j't'}) = \\left\\{\n  \\begin{array}{ll}\n  σ^2ρ^{|t-t'|} \\ \\ si \\ \\ (i, j) = (i', j') \\\\\n     0 \\ sinon \\\n   \\end{array}\n  \\right.\\]\nThis structure assumes that measurements made on different animals are independent. It is also assumed that |ρ| &lt; 1, which implies that the longer the time interval, the less correlated the tests on the same animal. This form of covariance corresponds to an autoregressive process of order 1, generally denoted AR(1). This model has two variance parameters: the temporal correlation ρ and the variance of each observation \\(σ^2\\).\n\\[\n  ψ = \\left( {\\begin{array}{cc}\n    ρ \\\\\n    σ^2 \\\\\n  \\end{array} } \\right)\n\\]\nBecause of the independence between the measurements obtained on different animals, the variance matrix Σ also has the same diagonal block shape, but the block (R) differs.\n\\[  \nR = \\left( {\\begin{array}{cc}\n     σ^2 & σ^2ρ & σ^2ρ^2 & ... & σ^2ρ^{T-1}\\\\\n     σ^2ρ & ... & ... & ... & ...\\\\\n     σ^2ρ^2 & ... & σ^2 & ... & σ^2ρ^2\\\\\n     ... & ... & ... & ... & σ^2ρ\\\\\n    σ^2ρ^{T-1} & ... & σ^2ρ^2 & σ^2ρ & σ^2\\\\\n  \\end{array} } \\right)\n\\]\nWe are going to use the BodyWeight dataset from the nlme package. In this dataset, weight is measured on 16 rats every 7 days during 64 days (which gives 11 measurements for each rats). Three diets are tested with 88 rats following diet 1 and 44 following diet 2 and 3.\nThe research question is: Is weight gain different depending on the diet? The model will be a mixed model with diet and time as fixed factor and individuals as random factor: weight ~ Diet * Time | Rat.\n\nhead(BodyWeight, 10)\n\nGrouped Data: weight ~ Time | Rat\n   weight Time Rat Diet\n1     240    1   1    1\n2     250    8   1    1\n3     255   15   1    1\n4     260   22   1    1\n5     262   29   1    1\n6     258   36   1    1\n7     266   43   1    1\n8     266   44   1    1\n9     265   50   1    1\n10    272   57   1    1\n\n\n\ntime_model = gls(weight ~ Diet * Time, data = BodyWeight, correlation = corAR1(form = ~ 1 | Rat))\nsummary(time_model)\n\nGeneralized least squares fit by REML\n  Model: weight ~ Diet * Time \n  Data: BodyWeight \n       AIC      BIC    logLik\n  1152.248 1177.334 -568.1239\n\nCorrelation Structure: AR(1)\n Formula: ~1 | Rat \n Parameter estimate(s):\n      Phi \n0.9895746 \n\nCoefficients:\n                Value Std.Error   t-value p-value\n(Intercept) 250.11069 13.327526 18.766475  0.0000\nDiet2       203.46561 23.083952  8.814158  0.0000\nDiet3       260.91151 23.083952 11.302723  0.0000\nTime          0.37351  0.090964  4.106160  0.0001\nDiet2:Time    0.62384  0.157554  3.959506  0.0001\nDiet3:Time    0.18780  0.157554  1.191998  0.2349\n\n Correlation: \n           (Intr) Diet2  Diet3  Time   Dt2:Tm\nDiet2      -0.577                            \nDiet3      -0.577  0.333                     \nTime       -0.222  0.128  0.128              \nDiet2:Time  0.128 -0.222 -0.074 -0.577       \nDiet3:Time  0.128 -0.074 -0.222 -0.577  0.333\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-1.44446363 -0.63038331  0.02804647  0.25238087  2.93319234 \n\nResidual standard error: 37.70413 \nDegrees of freedom: 176 total; 170 residual\n\n\nIn this example, the time correlation ρ has a value of 0.989. The sequence of weight values was highly correlated. The model allowed this temporal dependency to be taken into account. \n\n\n3.2 Case of spatial autocorrelation\nDependency structure We want to take into account the dependency due to the possible spatial proximity between the sites at which the measurements were taken.\nTo do this, \\(d(i, i')\\) is the distance separating sites \\(i\\) and \\(i'\\), and the following equation is used\n\\[Cov(Y_i, Y_i{'}) = e^{−δ.d(i,i')}\\]\nAs in the case of repeated measurements, there is no simple way of writing this in terms of random effects. Moreover, since all the measurements are dependent, the matrix Σ is no longer diagonal per block and is written as :\n\\[\n  Σ = \\left( {\\begin{array}{cc}\n     σ^2 + γ^2 & e^{−δ.d(i,i')}& ...& e^{−δ.d(i,i')}\\\\\n     e^{−δ.d(i,i')}& σ^2 + γ^2 & e^{−δ.d(i,i')} & \\vdots\\\\\n     \\vdots & e^{−δ.d(i,i')}  & σ^2 + γ^2 & e^{−δ.d(i,i')}\\\\\ne^{−δ.d(i,i')}& \\ldots & e^{−δ.d(i,i')} & σ^2 + γ^2\\\\\n  \\end{array} } \\right)\n\\]\n\ndata.spatialCor.glsExp &lt;- gls(y ~ x, data = data.spatialCor,\n    correlation = corExp(form = ~LAT + LONG, nugget = TRUE),\n    method = \"REML\")\n\n\nsummary(data.spatialCor.glsExp)\n\nGeneralized least squares fit by REML\n  Model: y ~ x \n  Data: data.spatialCor \n       AIC      BIC    logLik\n  974.3235 987.2484 -482.1618\n\nCorrelation Structure: Exponential spatial correlation\n Formula: ~LAT + LONG \n Parameter estimate(s):\n    range    nugget \n1.6956723 0.1280655 \n\nCoefficients:\n               Value Std.Error  t-value p-value\n(Intercept) 65.90018 21.824752 3.019516  0.0032\nx            0.94572  0.286245 3.303886  0.0013\n\n Correlation: \n  (Intr)\nx -0.418\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-1.6019483 -0.3507695  0.1608776  0.6451751  2.1331505 \n\nResidual standard error: 47.68716 \nDegrees of freedom: 100 total; 98 residual\n\n\nIn spatially correlated data, three coefficients are needed to describe the correlation structure. The variance increases with increasing distance up to a point the sill. The span of distances over which points are correlated is called the range. While we might expect the value of variance at a distance of zero to be zero, in reality we rarely have sampling units that approach such a small distance from one another.The value of variance when distance is equal to zero is the nugget.\nHere, in our example, the value of the sill, the range and the nugget are respectively 47.68, 1.69 and 0.12."
  },
  {
    "objectID": "Mixed_models.html#application",
    "href": "Mixed_models.html#application",
    "title": "Mixed models in ecology",
    "section": "4. Application",
    "text": "4. Application\nFor this example of a mixed model application, we will use a general linear mixed model. This is a special case of a general linear model, in which the response is quantitative and the predictor variables are both quantitative and qualitative, and the model includes random factors to take account of data dependency. Mixed models must respect the normality of residuals and the homogeneity of variances. (The structure and lines of code are inspired by (Outreman 2023)’s courses on linear mixed model.)\n\n4.1 Dataset presentation and objectives of the analysis\nFor this worked exercise, we will use data from a study performed on penguins. The aim of this study is to test whether species, sex and island influence the body mass of penguins. In the experimental design, the data are collected from one year to the next (from 2007 to 2009), which suggests that the penguin body mass data are dependent on each other from one year to the next. This dependency will be included in the model. The data contains:\n- species: three species of penguins (Chinstrap, Adelie, or Gentoo), categorical variable\n- island: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica), categorical variable\n- sex: penguin sex (female, or male), categorical variable\n- year: years of data collection (2007, 2008, or 2009), continuous variable\n- body_mass_g: body mass of the penguins (in grams), continuous variable\n\nThe response variable is the ‘body_mass_g’, while ‘species’ and ‘island’ and ‘sex’ are assumed predictors. To include data dependency, ‘year’ will be included as random factor in model. The underlying question for this research is: do the species, island and sex drive the body mass of penguins?\nData import :\n\n# Data import\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n# Make sure that our variables 'species', 'island' and 'sex' are all factors in the choice.\ndf$species=as.factor(df$species)\ndf$island=as.factor(df$island)\ndf$sex=as.factor(df$sex)\n\n# Check for missing values\ncolSums(is.na(df))\n\n            rowid           species            island    bill_length_mm \n                0                 0                 0                 2 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                2                 2                 2                11 \n             year \n                0 \n\n\nWe can see that there are some missing values, including 2 for the response variable \\(Y\\) ‘body_mass_g’ and 11 for the explanatory variable \\(X\\) ‘sex’. We’re going to delete the rows with the missing values.\n\n# Rows with missing values are marked.\nwhich(is.na(df$body_mass_g), arr.ind=TRUE)\n\n[1]   4 272\n\nwhich(is.na(df$sex), arr.ind=TRUE)\n\n [1]   4   9  10  11  12  48 179 219 257 269 272\n\n# We delete the rows 4, 9, 10, 11, 12, 48, 179, 219, 257, 269, and 272.\ndf=df[-c(4,9,10,11,12,48,179,219,257,269,272), ]\n\n# Check for missing values\ncolSums(is.na(df))\n\n            rowid           species            island    bill_length_mm \n                0                 0                 0                 0 \n    bill_depth_mm flipper_length_mm       body_mass_g               sex \n                0                 0                 0                 0 \n             year \n                0 \n\n# Ok\n\n\n\n4.2 Data exploration\nBefore any statistical analysis, it is ESSENTIAL to explore the data in order to avoid any errors. Here is the list of explorations to be carried out before modelling:\n\nCheck for outliers in \\(Y\\) and the distribution of \\(Y\\) values.\nIf \\(X\\) is an independent quantitative variable, check for the presence of outliers in X and the distribution of the values of X. 2b. 2b. If \\(X\\) is a qualitative independent variable, analyse the number of levels and the number of individuals per level.\nAnalyse the potential relationships between \\(Y\\) and the \\(X_{s}\\).\nCheck for the presence of interactions between \\(X_{s}\\).\nCheck for collinearity between \\(X_{s}\\).\n\n\n4.2.1 Outliers and distribution of \\(Y\\)\n\npar(mfrow=c(2,2))\n# Boxplot\nboxplot(df$body_mass_g,col='blue',ylab='Masse corporel')\n# Cleveland plot\ndotchart(df$body_mass_g,pch=16,col='blue',xlab='Masse corporel')\n# Histogram\nhist(df$body_mass_g,col='blue',xlab=\"Masse corporel\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(df$body_mass_g,pch=16,col='blue',xlab='')\nqqline(df$body_mass_g,col='red')\n\n\n\n\nHere, the Boxplot and Cleveland Plot show no individuals with outliers. The Cleveland Plot shows us that there appears to be a group of individuals with a body mass between 5000 and 6000g, while the rest is between 3000 and 4000g. The Histogram and the QQ Plot show that \\(Y\\) hardly follows a Normal distribution… This is not very important, as the validity of the model is based, among other things, on the normality of the residuals, which we will demonstrate later.\n\n\n4.2.2 Outliers in \\(Xs\\)\n\nFor \\(Xs\\) which are quantitative: check for outliers and distribution\n\nNo quantitative predictor here.\n\nFor categorical \\(Xs\\): number of levels and number of individuals per level.\n\n\n# Factor Species\nsummary(df$species)\n\n   Adelie Chinstrap    Gentoo \n      146        68       119 \n\n# Factor Island\nsummary(df$island)\n\n   Biscoe     Dream Torgersen \n      163       123        47 \n\n# Factor Sex\nsummary(df$sex)\n\nfemale   male \n   165    168 \n\n\nThe ‘species’ variable has 3 levels: Adelie, Chinstrap and Gentoo. The number of individuals between the 3 levels is not balanced, with fewer individuals for the Chinstrap species.\nThe ‘island’ variable has 3 levels: Biscoe, Dream and Torgersen. The number of individuals between the 3 levels is not balanced, with fewer individuals for the Torgersen island.\nThe ‘sex’ variable has 2 levels: female and male. The number of individuals per level is close to equilibrium.\n\n\n4.2.3 Analysis of potential relationships Y vs Xs\nWe can graphically analyse the possible relationships between Y and X. Please note that this graphical analysis of the relationships between Y and X in no way predicts the importance of the relationship. Statistical modelling is the only way to identify relationships.\n\npar(mfrow=c(1,1))\n# Species\nplot(df$body_mass_g~df$species,pch=16,col='blue',xlab='Espèces',ylab='Masse corporel en g')\n\n\n\n# Islands\nplot(df$body_mass_g~df$island,pch=16,col='blue',xlab='Îles',ylab='Masse corporel en g')\n\n\n\n# Sex\nplot(df$body_mass_g~df$sex,pch=16,col='blue',xlab='Sexe',ylab='Masse corporel en g')\n\n\n\n\nIn terms of species, we can see that Gentoo has a higher body mass (between 5000 and 6000g) than the other two species (between 3000 and 4000g). About the islands, we can see that the individuals present on Biscoe have a higher body mass (between 5000 and 6000g) than the individuals present on the other two islands (between 3000 and 4000g). Finally, in terms of sex, males appear to have a slightly higher body mass than females.\n\n\n4.2.4 Analysis of possible interactions between the three independent variables\nHere, we will consider the interaction between the three factors studied. To estimate the presence of interactive effects, we develop a graphical approach. Remember that the interaction between factors can only be tested if the factors are crossed (i.e. all the levels of one treatment are represented in all the levels of the other treatment and vice versa = a factorial design). This point must be tested first.\n\n# The experimental design means that the factors are cross-tabulated (all the levels of each variable are represented in all the levels of the other variables). \n\n# Interaction table\ntable(df$species,df$sex,df$island)\n\n, ,  = Biscoe\n\n           \n            female male\n  Adelie        22   22\n  Chinstrap      0    0\n  Gentoo        58   61\n\n, ,  = Dream\n\n           \n            female male\n  Adelie        27   28\n  Chinstrap     34   34\n  Gentoo         0    0\n\n, ,  = Torgersen\n\n           \n            female male\n  Adelie        24   23\n  Chinstrap      0    0\n  Gentoo         0    0\n\n# Interaction table without island\ntable(df$species,df$sex)\n\n           \n            female male\n  Adelie        73   73\n  Chinstrap     34   34\n  Gentoo        58   61\n\n# Interaction Species:Sex\nboxplot(df$body_mass_g~df$species*df$sex, varwidth = TRUE, xlab = \"Species.Sex\", ylab = \"Body mass\", col='blue2', main = \"\",cex.axis=0.7)\n\n\n\n\nIn the interaction table, we can see that in every island, not all the species are represented. This can be complicated to analyse. We’ll see in the next section if we remove the “Island” variable. We can see that without the ‘island’ variable, there is the same number of female and male in each species, except for the Gentoo species, with 58 female and 61 male.\nFor the interaction graph (still without the ‘island’ variable), we can see that males of all 3 species appear to have a greater body mass than females. We can also see that males and females of the Gentoo species have a higher body mass than individuals of the other species.\n\n\n4.2.5 Check collinearity between X\nColinearity refers to the situation in which two or more predictors of collinearity are closely related to each other.The presence of collinearity can pose problems in the context of regression, as it can be difficult to separate the individual effects of collinear variables on the response.\nHere, we will test for collinearity between our 3 predictor variables:\n\n# ploting Species by Island\nggplot(df, aes(x=species, y=island)) +\n  geom_point() +\n  theme_bw() -&gt; p1\n\n# ploting Species by Sex\nggplot(df, aes(x=species, y=sex)) +\n  geom_point() +\n  theme_bw() -&gt; p2\n\n# ploting Island by Sex\nggplot(df, aes(x=island, y=sex)) +\n  geom_point() +\n  theme_bw() -&gt; p3\n\n# Ploting side-by-side\nmarrangeGrob(list(p1,p2,p3), nrow=1, ncol=3, top=NULL)\n\n\n\n\nIn our example, we can see that for the interaction between Species and Sex, there are two sex modalities per species, and for the interaction between Island and Sex, there are two sex modalities per island. However, for the interaction between Species and islands based on, not all the islands contain all the species, as we saw in the previous section! We cannot therefore test the influence of islands and species on the basis of this result. We therefore decided to remove the Island variable from our analysis. We will test the influence of species and sex on the body mass of penguins, always with years as a random effect.\n\n\n\n4.3 Statistical analysis\n\n4.3.1 Model construction\nFor statistical modelling, we first analyse the full model (model containing all the independent variables to be tested).\nTo obtain the candidate model (a model containing only the significant terms) from the full model, we will use the BACKWARD SELECTION METHOD, i.e. model selection based on the significance of the terms. In this approach, we start by creating the full model with all the variables of interest, then drop the least significant variable as long as it is not significant. We continue by successively fitting reduced models and applying the same rule until all the remaining variables are significant. The deletion of non-significant terms must follow the following two steps: - First, insignificant interactions are successively removed. - Secondly, the non-significant main effects are successively removed. A main effect is only removed if it is insignificant AND if it is not contained in a significant interaction.\nIn this example, we consider a measure of dependence at year level (e.g. a mass measurement made in 2009 depends on the measurement made in 2008, which in turn depends on the measurement made in 2007). The presence of the random effect of the year will be integrated not with the lm function, but lme (from the nlme package).\n\n# Full model\nmod1=lme(body_mass_g~species\n              + sex\n              + species:sex\n              ,random=~1|year\n              ,data=df)\n\nWe can see from the anova output of our full model that each interaction and each variable is significant (&lt;0.05). The full model is therefore the candidate model.\n\n\n4.3.2 Model’s coefficients analysis\n\n# Coefficients of the model\nsummary(mod1)\n\nLinear mixed-effects model fit by REML\n  Data: df \n       AIC      BIC    logLik\n  4718.236 4748.556 -2351.118\n\nRandom effects:\n Formula: ~1 | year\n        (Intercept) Residual\nStdDev:   0.0140241 309.3973\n\nFixed effects:  body_mass_g ~ species + sex + species:sex \n                            Value Std.Error  DF  t-value p-value\n(Intercept)              3368.836  36.21222 325 93.03036  0.0000\nspeciesChinstrap          158.370  64.24029 325  2.46528  0.0142\nspeciesGentoo            1310.906  54.42228 325 24.08767  0.0000\nsexmale                   674.658  51.21181 325 13.17387  0.0000\nspeciesChinstrap:sexmale -262.893  90.84950 325 -2.89372  0.0041\nspeciesGentoo:sexmale     130.437  76.43559 325  1.70650  0.0889\n Correlation: \n                         (Intr) spcsCh spcsGn sexmal spcsC:\nspeciesChinstrap         -0.564                            \nspeciesGentoo            -0.665  0.375                     \nsexmale                  -0.707  0.399  0.471              \nspeciesChinstrap:sexmale  0.399 -0.707 -0.265 -0.564       \nspeciesGentoo:sexmale     0.474 -0.267 -0.712 -0.670  0.378\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.67360404 -0.69157224  0.03564805  0.66744876  2.78292473 \n\nNumber of Observations: 333\nNumber of Groups: 3 \n\n\nFrom this table, we can determine the coefficients of the model such that:\nSpecies factor\n- \\(species_{Adelie}\\) = 0 (the baseline of the factor Habitat) - \\(Species_{Chinstrap}\\) = \\(158.370\\) - \\(Species_{Gentoo}\\) = \\(1310.906\\)\nSex factor\n- \\(Sex_{female}\\) = 0 (the baseline of the factor Habitat) - \\(Sex_{male}\\) = \\(674.658\\)\nInteraction\n- \\(Species_{Chinstrap}\\):\\(Sex_{male}\\) = \\(-262.893\\) - \\(Species_{Gentoo}\\):\\(Sex_{male}\\) = \\(130.437^{NS}\\)\nSo, the candidate model is: \\[  Species = 3369 + (Adelie = 0, Chinstrap = 158, Gentoo = 1311)  + (Female = 0,\\: Male = 675)\\] \\[       + (Adelie_{Male} = 0, \\:Chinstrap_{Male} = -263,\\: Gentoo_{Male} = 130^{NS}) \\]\nFor sake of simplicity, we can write the model depending on the sexe :\nThe model for the Female pinguin is : \\[ Sex_{Female} = 3369\\:  + (Adelie = 0,\\: Chinstrap = 158,\\: Gentoo = 1311)\\]\nThe model for the Male pinguin is : \\[Sex_{Male} = 4043\\: + (Adelie = 0,\\: Chinstrap = - 105,\\: Gentoo = 1441)\\]\nThus, sex, species, and the interaction of these two variables (except between Male and Gentoo) do have a significant impact on penguin body mass. For example, in Adelie penguins, the female will have a body mass of 3369g, whereas a male will have a body mass of 4043g and in Chinstrap penguins, the female will have a body mass of 3527g, whereas a male will have a body mass of 3938g.\nThese results are in line with the graph obtained in the “interactions between factors” section, which showed that males had a greater body mass than females. This also confirms that individuals of the Gentoo species have a greater body mass than individuals (males and females) of the other two species.\n\n\n\n4.4 Model validation\nTo validate the model, we need to :\n\nValidate the normality of the residuals\nHistogram and QQplot of the residuals\nValidate the homogeneity of the variances\nIn addition, check for the presence of observations which would have contributed too much to the model.\n\n\n4.4.1 Normality of the residuals\n\npar(mfrow=c(1,2))\n# Histogram\nhist(mod1$residuals,col='blue',xlab=\"residuals\",main=\"Check Normality\")\n# Quantile-Quantile plot\nqqnorm(mod1$residuals,pch=16,col='blue',xlab='')\nqqline(mod1$residuals,col='red')\n\n\n\n\nWe can see that the histogram follows a normal distribution, and the quantile plot points follow the red line: the normality of the residuals is validated.\n\n\n4.4.2 Homogeneity of the variance\n\npar(mfrow=c(1,3))\n\n# residuals vs fitted\nplot(residuals(mod1)~fitted(mod1)\n      , col='blue'\n      , pch=16)\nabline(h = 0)\n\n# residuals against Species\nboxplot(residuals(mod1)~ df$species, \n         varwidth = TRUE,\n         ylab = \"Residuals\",\n         xlab = \"Species\",\n         main = \"\")\nabline(h = 0)\n\n# residuals against Sex\nboxplot(residuals(mod1)~ df$sex, \n         varwidth = TRUE,\n         ylab = \"Residuals\",\n         xlab = \"Sex\",\n         main = \"\")\nabline(h = 0)\n\n\n\n\nWe can see here that for each plot, the variance of the residuals is evenly distributed around the horizontal line. The homogeneity of the variance is validated.\n\n\n4.4.3 Look at influential observations\n\npar(mfrow = c(1, 1))\n\n\nCookD(mod1,newwd=TRUE)\n\nWe can see that individuals 314, 315 and 325 contribute slightly more to the model, but this is not an aberrant result."
  },
  {
    "objectID": "chapter_dependance.html",
    "href": "chapter_dependance.html",
    "title": "Chapter : statistical tests with dependent data",
    "section": "",
    "text": "This chapter is a simple example using R\nYou can import R package using the code\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "chapter_dependance.html#what-is-autocorrelation",
    "href": "chapter_dependance.html#what-is-autocorrelation",
    "title": "Chapter : statistical tests with dependent data",
    "section": "What is autocorrelation ?",
    "text": "What is autocorrelation ?\nStatistical analyses, including many regression methods, often assume that observations are independent of each other. So it is natural to make independence calculations between data X and Y. But there may still be a dependency intrinsic to each data item: this is known as autocorrelation. Autocorrelation indicates that the independence assumption is not satisfied, which can lead to biased parameter estimates, incorrect confidence intervals and a loss of statistical power. Autocorrelation in statistics is a measure of the linear dependence between the values of a single variable itself, at different times or locations. Autocorrelation is only detected on the variable being measured, i.e. the quantitative response variable. Checking for autocorrelation in a variable means analyzing the relationship between an observation and other previous observations in the series. This means analyzing the possible link between what is measured at time 1 and what is measured at time 2, to see if data 2 can be predicted with what we know about data 1, if they are close in space or time. Correlation between two observations is often expressed as a correlation coefficient, such as Pearson’s correlation coefficient. Values are correlated with an offset function in time or space, giving an autocorrelation coefficient which may be positive, indicating that the observations tend to be similar, or negative, indicating that the observations tend to be opposite to each other."
  },
  {
    "objectID": "chapter_dependance.html#what-types-of-autocorrelation",
    "href": "chapter_dependance.html#what-types-of-autocorrelation",
    "title": "Chapter : statistical tests with dependent data",
    "section": "What types of autocorrelation ?",
    "text": "What types of autocorrelation ?\nAutocorrelation is commonly used to analyze data where the order or location of observations has an important significance, such as time series (data taken at the same location at several points in time), or spatial data (data taken at a given point in time at several locations in the same geographical area, and therefore close in space).\n\nTime series\nIn time series, there may be seasonal autocorrelation, where values observed at the same time each year (seasons) are correlated. Temporal autocorrelation shows spatial similarities that depend on the scale used. Temporal autocorrelation in ecology is important for understanding the processes of reproduction, migration, population dispersal and species responses to seasonal environmental changes. Spatial dependencies can be linked to several factors: [Image]\n\nExample of temporal autocorrelation\nAn example of temporal autocorrelation in ecology concerns populations of animal or plant species, particularly when studying seasonal variations. Let’s imagine a study of annual fluctuations in the population of migratory birds in a given region. Temporal autocorrelation means that the number of birds observed at a given time of the year is correlated with the number of birds observed at the same time of the previous year. Suppose the data show positive temporal autocorrelation for a migratory bird species. This would mean that if, for example, in April of the current year, a large number of these birds are observed, it is highly likely that in April of the previous year, a large number of these same birds were also observed. This temporal dependence may be due to seasonal bird migrations, the availability of food resources or other cyclical environmental factors.\n\n\n\nSpatial dependence\nIn the case of spatial data, spatial autocorrelation refers to the correlation between observations in close spatial locations. This can be important for understanding the spatial distribution of populations, environmental phenomena and so on. Spatial autocorrelation shows temporal similarities that depend on the scale used. Spatial autocorrelation is important for understanding patterns of species distribution, population dispersal, biotic interactions and ecological processes at different spatial scales. - It can be due to various factors, such as : - Microclimate effects: (local characteristics of terrain, vegetation or topography can influence temperature on a small scale) - Dispersion phenomena: (the propagation of heat, wind, humidity or other environmental factors can cause spatial autocorrelation) - Biotic interactions: (interactions between plant, animal and micro-organism species in an ecosystem can also influence the spatial distribution of variables such as temperature).\n\nExample of spatial dependence\nAn example of spatial autocorrelation is the observation of temperature distribution in a large forest. Let’s imagine a large, dense forest with many weather stations measuring temperatures at different locations. Spatial autocorrelation would manifest itself in the fact that temperatures recorded at nearby locations in the forest are correlated, i.e. they tend to be similar. Suppose the data show positive spatial autocorrelation. This would mean that, if you have two weather stations located close to each other (say, a few meters apart), the temperatures measured at these two stations at any given time are highly positively correlated. In other words, when one of the stations records a high temperature, the other station will also tend to record a high temperature, and vice versa."
  },
  {
    "objectID": "chapter_dependance.html#why-is-this-important",
    "href": "chapter_dependance.html#why-is-this-important",
    "title": "Chapter : statistical tests with dependent data",
    "section": "Why is this important?",
    "text": "Why is this important?\n…"
  }
]